{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d642343-c207-43a8-a7fe-bbe490d3a578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/zhy542/.local/lib/python3.11/site-packages (4.46.3)\n",
      "Requirement already satisfied: peft in /home/zhy542/.local/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: bitsandbytes in /home/zhy542/.local/lib/python3.11/site-packages (0.44.1)\n",
      "Requirement already satisfied: trl in /home/zhy542/.local/lib/python3.11/site-packages (0.12.1)\n",
      "Requirement already satisfied: deepeval in /home/zhy542/.local/lib/python3.11/site-packages (1.5.9)\n",
      "Requirement already satisfied: datasets in /home/zhy542/.local/lib/python3.11/site-packages (3.1.0)\n",
      "Requirement already satisfied: torch in /home/zhy542/.local/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: rouge_score in /home/zhy542/.local/lib/python3.11/site-packages (0.1.2)\n",
      "Requirement already satisfied: bert_score in /home/zhy542/.local/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: filelock in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/zhy542/.local/lib/python3.11/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zhy542/.local/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/zhy542/.local/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/zhy542/.local/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/zhy542/.local/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/zhy542/.local/lib/python3.11/site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: psutil in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/zhy542/.local/lib/python3.11/site-packages (from peft) (1.1.1)\n",
      "Requirement already satisfied: rich in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from trl) (13.3.5)\n",
      "Requirement already satisfied: pytest in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from deepeval) (7.4.0)\n",
      "Requirement already satisfied: tabulate in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from deepeval) (0.9.0)\n",
      "Requirement already satisfied: typer in /home/zhy542/.local/lib/python3.11/site-packages (from deepeval) (0.13.1)\n",
      "Requirement already satisfied: protobuf in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from deepeval) (3.20.3)\n",
      "Requirement already satisfied: pydantic in /home/zhy542/.local/lib/python3.11/site-packages (from deepeval) (2.10.1)\n",
      "Requirement already satisfied: sentry-sdk in /home/zhy542/.local/lib/python3.11/site-packages (from deepeval) (2.19.0)\n",
      "Requirement already satisfied: pytest-repeat in /home/zhy542/.local/lib/python3.11/site-packages (from deepeval) (0.9.3)\n",
      "Requirement already satisfied: pytest-xdist in /home/zhy542/.local/lib/python3.11/site-packages (from deepeval) (3.6.1)\n",
      "Requirement already satisfied: portalocker in /home/zhy542/.local/lib/python3.11/site-packages (from deepeval) (3.0.0)\n",
      "Requirement already satisfied: langchain in /home/zhy542/.local/lib/python3.11/site-packages (from deepeval) (0.3.8)\n",
      "Requirement already satisfied: langchain-core in /home/zhy542/.local/lib/python3.11/site-packages (from deepeval) (0.3.21)\n",
      "Requirement already satisfied: langchain-openai in /home/zhy542/.local/lib/python3.11/site-packages (from deepeval) (0.2.9)\n",
      "Requirement already satisfied: ragas in /home/zhy542/.local/lib/python3.11/site-packages (from deepeval) (0.2.6)\n",
      "Requirement already satisfied: docx2txt~=0.8 in /home/zhy542/.local/lib/python3.11/site-packages (from deepeval) (0.8)\n",
      "Requirement already satisfied: importlib-metadata>=6.0.2 in /home/zhy542/.local/lib/python3.11/site-packages (from deepeval) (7.0.0)\n",
      "Requirement already satisfied: tenacity~=8.4.1 in /home/zhy542/.local/lib/python3.11/site-packages (from deepeval) (8.4.2)\n",
      "Requirement already satisfied: opentelemetry-api~=1.24.0 in /home/zhy542/.local/lib/python3.11/site-packages (from deepeval) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.24.0 in /home/zhy542/.local/lib/python3.11/site-packages (from deepeval) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc~=1.24.0 in /home/zhy542/.local/lib/python3.11/site-packages (from deepeval) (1.24.0)\n",
      "Requirement already satisfied: grpcio~=1.63.0 in /home/zhy542/.local/lib/python3.11/site-packages (from deepeval) (1.63.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/zhy542/.local/lib/python3.11/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/zhy542/.local/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: xxhash in /home/zhy542/.local/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/zhy542/.local/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/zhy542/.local/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/zhy542/.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/zhy542/.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/zhy542/.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/zhy542/.local/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/zhy542/.local/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/zhy542/.local/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/zhy542/.local/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/zhy542/.local/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/zhy542/.local/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/zhy542/.local/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/zhy542/.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/zhy542/.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/zhy542/.local/lib/python3.11/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/zhy542/.local/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: absl-py in /home/zhy542/.local/lib/python3.11/site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: nltk in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from bert_score) (3.8.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from importlib-metadata>=6.0.2->deepeval) (3.17.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/zhy542/.local/lib/python3.11/site-packages (from opentelemetry-api~=1.24.0->deepeval) (1.2.15)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/zhy542/.local/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in /home/zhy542/.local/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.24.0 in /home/zhy542/.local/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /home/zhy542/.local/lib/python3.11/site-packages (from opentelemetry-sdk~=1.24.0->deepeval) (0.45b0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from langchain->deepeval) (2.0.25)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /home/zhy542/.local/lib/python3.11/site-packages (from langchain->deepeval) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/zhy542/.local/lib/python3.11/site-packages (from langchain->deepeval) (0.1.145)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/zhy542/.local/lib/python3.11/site-packages (from langchain-core->deepeval) (1.33)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/zhy542/.local/lib/python3.11/site-packages (from pydantic->deepeval) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/zhy542/.local/lib/python3.11/site-packages (from pydantic->deepeval) (2.27.1)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /home/zhy542/.local/lib/python3.11/site-packages (from langchain-openai->deepeval) (1.55.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/zhy542/.local/lib/python3.11/site-packages (from langchain-openai->deepeval) (0.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from matplotlib->bert_score) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from matplotlib->bert_score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from matplotlib->bert_score) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from matplotlib->bert_score) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from matplotlib->bert_score) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from matplotlib->bert_score) (3.0.9)\n",
      "Requirement already satisfied: click in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: iniconfig in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from pytest->deepeval) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from pytest->deepeval) (1.0.0)\n",
      "Requirement already satisfied: execnet>=2.1 in /home/zhy542/.local/lib/python3.11/site-packages (from pytest-xdist->deepeval) (2.1.1)\n",
      "Requirement already satisfied: langchain-community in /home/zhy542/.local/lib/python3.11/site-packages (from ragas->deepeval) (0.3.8)\n",
      "Requirement already satisfied: nest-asyncio in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from ragas->deepeval) (1.6.0)\n",
      "Requirement already satisfied: appdirs in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from ragas->deepeval) (1.4.4)\n",
      "Requirement already satisfied: pysbd>=0.3.4 in /home/zhy542/.local/lib/python3.11/site-packages (from ragas->deepeval) (0.3.4)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from rich->trl) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from rich->trl) (2.15.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/zhy542/.local/lib/python3.11/site-packages (from typer->deepeval) (1.5.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api~=1.24.0->deepeval) (1.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->deepeval) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/zhy542/.local/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->deepeval) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/zhy542/.local/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->deepeval) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->deepeval) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->trl) (0.1.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai->deepeval) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai->deepeval) (1.8.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/zhy542/.local/lib/python3.11/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai->deepeval) (0.7.1)\n",
      "Requirement already satisfied: sniffio in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai->deepeval) (1.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain->deepeval) (3.0.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/zhy542/.local/lib/python3.11/site-packages (from langchain-community->ragas->deepeval) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /home/zhy542/.local/lib/python3.11/site-packages (from langchain-community->ragas->deepeval) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/zhy542/.local/lib/python3.11/site-packages (from langchain-community->ragas->deepeval) (2.6.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/zhy542/.local/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/zhy542/.local/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval) (0.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/zhy542/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->deepeval) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/zhy542/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->deepeval) (0.14.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas->deepeval) (0.21.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /apps/anaconda3/2024.02-1/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers peft bitsandbytes trl deepeval datasets torch rouge_score bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc93721-bec6-4ae7-b372-b5f6595909b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "\n",
    "import numpy as np\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_score\n",
    "#from moverscore_v2 import get_idf_dict, word_mover_score\n",
    "\n",
    "# hugging-face token = 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5967d08-67b7-45f4-a3dc-5465c4831fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "### Setup Quantization Config ###\n",
    "#################################\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1969ae2-3534-43d2-becd-478d9bf48ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#######################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m### Load Base Model ###\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#######################\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#base_model = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/zhy542/.llama/checkpoints/Llama3.1-8B\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m llama_3 \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      7\u001b[0m     base_model,\n\u001b[1;32m      8\u001b[0m     quantization_config\u001b[38;5;241m=\u001b[39mquant_config,\n\u001b[1;32m      9\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0\u001b[39m}\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    566\u001b[0m     )\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/modeling_utils.py:3657\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3654\u001b[0m     hf_quantizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3657\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mvalidate_environment(\n\u001b[1;32m   3658\u001b[0m         torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype, from_tf\u001b[38;5;241m=\u001b[39mfrom_tf, from_flax\u001b[38;5;241m=\u001b[39mfrom_flax, device_map\u001b[38;5;241m=\u001b[39mdevice_map\n\u001b[1;32m   3659\u001b[0m     )\n\u001b[1;32m   3660\u001b[0m     torch_dtype \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_torch_dtype(torch_dtype)\n\u001b[1;32m   3661\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_device_map(device_map)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:82\u001b[0m, in \u001b[0;36mBnb4BitHfQuantizer.validate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_bitsandbytes_multi_backend_available\n\u001b[1;32m     81\u001b[0m bnb_multibackend_is_enabled \u001b[38;5;241m=\u001b[39m is_bitsandbytes_multi_backend_available()\n\u001b[0;32m---> 82\u001b[0m validate_bnb_backend_availability(raise_exception\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_tf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_flax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting into 4-bit or 8-bit weights from tf/flax weights is currently not supported, please make\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m sure the weights are in PyTorch format.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/integrations/bitsandbytes.py:558\u001b[0m, in \u001b[0;36mvalidate_bnb_backend_availability\u001b[0;34m(raise_exception)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bitsandbytes_multi_backend_available():\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _validate_bnb_multi_backend_availability(raise_exception)\n\u001b[0;32m--> 558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _validate_bnb_cuda_backend_availability(raise_exception)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/integrations/bitsandbytes.py:536\u001b[0m, in \u001b[0;36m_validate_bnb_cuda_backend_availability\u001b[0;34m(raise_exception)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_exception:\n\u001b[1;32m    535\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(log_msg)\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(log_msg)\n\u001b[1;32m    538\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarning(log_msg)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "### Load Base Model ###\n",
    "#######################\n",
    "base_model = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "llama_3 = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=quant_config,\n",
    "    device_map={\"\":0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d65578f1-9c73-4ffa-954b-5d5de0326e6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-67428ad7-7de6e5991e7947216cb6b55a;0470d565-f232-40ca-b7eb-cb4890a49239)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/utils/hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    404\u001b[0m         path_or_repo_id,\n\u001b[1;32m    405\u001b[0m         filename,\n\u001b[1;32m    406\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[1;32m    407\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    408\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    409\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    410\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    411\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    412\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    413\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    414\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    415\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    416\u001b[0m     )\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:862\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[1;32m    863\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    864\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;66;03m# File info\u001b[39;00m\n\u001b[1;32m    866\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[1;32m    867\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m    868\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    869\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;66;03m# HTTP info\u001b[39;00m\n\u001b[1;32m    871\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[1;32m    872\u001b[0m         etag_timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[1;32m    873\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    874\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    875\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    876\u001b[0m         \u001b[38;5;66;03m# Additional options\u001b[39;00m\n\u001b[1;32m    877\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    878\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    879\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:969\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[0;32m--> 969\u001b[0m     _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1484\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1482\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1483\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1484\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1486\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1376\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1376\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m get_hf_file_metadata(\n\u001b[1;32m   1377\u001b[0m         url\u001b[38;5;241m=\u001b[39murl, proxies\u001b[38;5;241m=\u001b[39mproxies, timeout\u001b[38;5;241m=\u001b[39metag_timeout, headers\u001b[38;5;241m=\u001b[39mheaders, token\u001b[38;5;241m=\u001b[39mtoken\n\u001b[1;32m   1378\u001b[0m     )\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1296\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1296\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1297\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1298\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   1299\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1300\u001b[0m     allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1301\u001b[0m     follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1302\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1303\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m   1304\u001b[0m )\n\u001b[1;32m   1305\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:277\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 277\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m    278\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    279\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    280\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:301\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    300\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 301\u001b[0m hf_raise_for_status(response)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:423\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    420\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    421\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    422\u001b[0m     )\n\u001b[0;32m--> 423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(GatedRepoError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_message \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to this resource is disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-67428ad7-7de6e5991e7947216cb6b55a;0470d565-f232-40ca-b7eb-cb4890a49239)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m######################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m### Load Tokenizer ###\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m######################\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      5\u001b[0m   base_model, \n\u001b[1;32m      6\u001b[0m   trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token\n\u001b[1;32m      9\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpadding_side \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:877\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    875\u001b[0m         config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfor_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_dict)\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 877\u001b[0m         config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    878\u001b[0m             pretrained_model_name_or_path, trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m config_tokenizer_class \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtokenizer_class\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py:1017\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1015\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1017\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m PretrainedConfig\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1018\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1019\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/configuration_utils.py:574\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 574\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/configuration_utils.py:633\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m    634\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    635\u001b[0m         configuration_file,\n\u001b[1;32m    636\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    637\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    638\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    639\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    640\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    641\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    642\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    643\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    644\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m    645\u001b[0m         _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/utils/hub.py:421\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_gated_repo:\n\u001b[1;32m    420\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n\u001b[0;32m--> 421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    431\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-67428ad7-7de6e5991e7947216cb6b55a;0470d565-f232-40ca-b7eb-cb4890a49239)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in."
     ]
    }
   ],
   "source": [
    "######################\n",
    "### Load Tokenizer ###\n",
    "######################\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  base_model, \n",
    "  trust_remote_code=True\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40a09298-ba96-473e-b8b4-4343506204a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to find '/home/zhy542/Downloads/./Datasets/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m####################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m### Load Dataset ###\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m####################\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, data_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Datasets/train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:2132\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2127\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[1;32m   2128\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2129\u001b[0m )\n\u001b[1;32m   2131\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2132\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m load_dataset_builder(\n\u001b[1;32m   2133\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[1;32m   2134\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   2135\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[1;32m   2136\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[1;32m   2137\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   2138\u001b[0m     features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[1;32m   2139\u001b[0m     download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[1;32m   2140\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[1;32m   2141\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   2142\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   2143\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m   2144\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[1;32m   2145\u001b[0m     _require_default_config_name\u001b[38;5;241m=\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2146\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_kwargs,\n\u001b[1;32m   2147\u001b[0m )\n\u001b[1;32m   2149\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:1853\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   1851\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1852\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 1853\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m dataset_module_factory(\n\u001b[1;32m   1854\u001b[0m     path,\n\u001b[1;32m   1855\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   1856\u001b[0m     download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[1;32m   1857\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[1;32m   1858\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[1;32m   1859\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[1;32m   1860\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   1861\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[1;32m   1862\u001b[0m     _require_default_config_name\u001b[38;5;241m=\u001b[39m_require_default_config_name,\n\u001b[1;32m   1863\u001b[0m     _require_custom_configs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(config_kwargs),\n\u001b[1;32m   1864\u001b[0m )\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:1562\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;66;03m# We have several ways to get a dataset builder:\u001b[39;00m\n\u001b[1;32m   1540\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;66;03m# - if path is the name of a packaged dataset module\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1553\u001b[0m \n\u001b[1;32m   1554\u001b[0m \u001b[38;5;66;03m# Try packaged\u001b[39;00m\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m _PACKAGED_DATASETS_MODULES:\n\u001b[1;32m   1556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PackagedDatasetModuleFactory(\n\u001b[1;32m   1557\u001b[0m         path,\n\u001b[1;32m   1558\u001b[0m         data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[1;32m   1559\u001b[0m         data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[1;32m   1560\u001b[0m         download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[1;32m   1561\u001b[0m         download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[0;32m-> 1562\u001b[0m     )\u001b[38;5;241m.\u001b[39mget_module()\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;66;03m# Try locally\u001b[39;00m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mendswith(filename):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:942\u001b[0m, in \u001b[0;36mPackagedDatasetModuleFactory.get_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m base_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexpanduser()\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mas_posix()\n\u001b[1;32m    937\u001b[0m patterns \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    938\u001b[0m     sanitize_patterns(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files)\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m get_data_patterns(base_path, download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config)\n\u001b[1;32m    941\u001b[0m )\n\u001b[0;32m--> 942\u001b[0m data_files \u001b[38;5;241m=\u001b[39m DataFilesDict\u001b[38;5;241m.\u001b[39mfrom_patterns(\n\u001b[1;32m    943\u001b[0m     patterns,\n\u001b[1;32m    944\u001b[0m     download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config,\n\u001b[1;32m    945\u001b[0m     base_path\u001b[38;5;241m=\u001b[39mbase_path,\n\u001b[1;32m    946\u001b[0m )\n\u001b[1;32m    947\u001b[0m supports_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m _MODULE_SUPPORTS_METADATA\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m supports_metadata \u001b[38;5;129;01mand\u001b[39;00m patterns \u001b[38;5;241m!=\u001b[39m DEFAULT_PATTERNS_ALL:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/data_files.py:721\u001b[0m, in \u001b[0;36mDataFilesDict.from_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    716\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, patterns_for_key \u001b[38;5;129;01min\u001b[39;00m patterns\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    718\u001b[0m     out[key] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    719\u001b[0m         patterns_for_key\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(patterns_for_key, DataFilesList)\n\u001b[0;32m--> 721\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m DataFilesList\u001b[38;5;241m.\u001b[39mfrom_patterns(\n\u001b[1;32m    722\u001b[0m             patterns_for_key,\n\u001b[1;32m    723\u001b[0m             base_path\u001b[38;5;241m=\u001b[39mbase_path,\n\u001b[1;32m    724\u001b[0m             allowed_extensions\u001b[38;5;241m=\u001b[39mallowed_extensions,\n\u001b[1;32m    725\u001b[0m             download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[1;32m    726\u001b[0m         )\n\u001b[1;32m    727\u001b[0m     )\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/data_files.py:624\u001b[0m, in \u001b[0;36mDataFilesList.from_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m patterns:\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         data_files\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 624\u001b[0m             resolve_pattern(\n\u001b[1;32m    625\u001b[0m                 pattern,\n\u001b[1;32m    626\u001b[0m                 base_path\u001b[38;5;241m=\u001b[39mbase_path,\n\u001b[1;32m    627\u001b[0m                 allowed_extensions\u001b[38;5;241m=\u001b[39mallowed_extensions,\n\u001b[1;32m    628\u001b[0m                 download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[1;32m    629\u001b[0m             )\n\u001b[1;32m    630\u001b[0m         )\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_magic(pattern):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/data_files.py:411\u001b[0m, in \u001b[0;36mresolve_pattern\u001b[0;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allowed_extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m         error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with any supported extension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(allowed_extensions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 411\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(error_msg)\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Unable to find '/home/zhy542/Downloads/./Datasets/train.csv'"
     ]
    }
   ],
   "source": [
    "####################\n",
    "### Load Dataset ###\n",
    "####################\n",
    "train_dataset = load_dataset(\"csv\", data_files=\"./Datasets/train.csv\", split=\"train\") #, streaming=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4faf5d6d-1e5d-4df0-adc3-c17e0f517fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"(Jan 30, 2020  7:00 PM) Fred Silverman, who steered programming for each of the Big Three broadcast networks and brought All in the Family, Roots, Hawaii Five-O and other hit series and miniseries to television, died Thursday. He was 82. Silverman, who had been battling cancer, died at his home in the Pacific Palisades area of Los Angeles, the AP reports. Silverman's gift for picking winners prompted Time magazine to dub him  The Man with the Golden Gut  in a 1977 profile. As ABC's entertainment chief, Silverman turned the network’s fortunes around with shows including Roots, Rich Man, Poor Man and Charlie’s Angels. He had already brought success to CBS with an overhaul that included replacing country-themed series such as Green Acres with what advertisers considered more upscale and urban fare, including The Mary Tyler Moore Show, The Bob Newhart Show and Mannix. He couldn't repeat that success when he moved to NBC.\", 'summary': 'Fred Silverman Put a Series of Hits on All 3 Major Networks', 'cloze': 'Fred Silverman Put a Series of Hits on All ____ Major Networks', 'cloze_gt': '3', 'cloze_annotation': 'Trans( Three )', 'need_reasoning': 1}\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "### Sample from Dataset ###\n",
    "###########################\n",
    "print(next(iter(train_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b8d9e3-e9a4-47a7-81b1-1a7d7d946ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "### Load LoRA Configurations for PEFT ###\n",
    "#########################################\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout= 0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8e53122-6796-4c11-bdfb-4c50971a6ba3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llama_3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 28\u001b[0m\n\u001b[1;32m      4\u001b[0m training_arguments \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      5\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/zhy542/tuning_results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     lr_scheduler_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m##########################\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m### Set SFT Parameters ###\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m##########################\u001b[39;00m\n\u001b[1;32m     27\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SFTTrainer(\n\u001b[0;32m---> 28\u001b[0m     model\u001b[38;5;241m=\u001b[39mllama_3,\n\u001b[1;32m     29\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m     30\u001b[0m     peft_config\u001b[38;5;241m=\u001b[39mpeft_config,\n\u001b[1;32m     31\u001b[0m     dataset_text_field\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, \u001b[38;5;66;03m# was set to None\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     34\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_arguments,\n\u001b[1;32m     35\u001b[0m     packing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     36\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llama_3' is not defined"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "### Set Training Arguments ###\n",
    "##############################\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"/home/zhy542/tuning_results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=25,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,    \n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\"\n",
    ")\n",
    "\n",
    "\n",
    "##########################\n",
    "### Set SFT Parameters ###\n",
    "##########################\n",
    "trainer = SFTTrainer(\n",
    "    model=llama_3,\n",
    "    train_dataset=train_dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024, # was set to None\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11f2e8bf-d5cc-463d-b8d3-819f7eed95ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9711' max='9711' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9711/9711 4:01:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.328800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>2.206600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.132100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>2.194900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.072300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>2.182200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.087300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>2.080500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.112700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.122400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.069400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.213700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.136700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.037300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.102800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.180800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.071500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.142300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.040200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.097200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>2.108700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.075800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.170900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.986100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>2.133600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.110400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.992100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2.125800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.064600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>2.123900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.008300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>2.055100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.079300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>2.115600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>2.065700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.056100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>2.091000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.051500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>2.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.072500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>2.109600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.975200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>2.057100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.013300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>2.117800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>2.082600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>1.966100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>2.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>2.085700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.003600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>2.171600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.028900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>2.107700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>2.112600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>2.126500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>2.140700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>2.065200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>2.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.069500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>2.113300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>2.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>2.124300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.985900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>2.070800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>2.008500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>2.066400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.103100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>2.132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>2.080700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>2.095900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.957800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>2.123300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>1.971300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>2.024500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.970500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2125</td>\n",
       "      <td>2.119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>2.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2175</td>\n",
       "      <td>1.970900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.042700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2225</td>\n",
       "      <td>2.134100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>2.033200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2275</td>\n",
       "      <td>2.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>2.055900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2325</td>\n",
       "      <td>2.124300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>1.909300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2375</td>\n",
       "      <td>2.099100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2425</td>\n",
       "      <td>2.031700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>1.962500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>2.098900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2525</td>\n",
       "      <td>2.103200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>1.996800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2575</td>\n",
       "      <td>2.115700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2625</td>\n",
       "      <td>2.087300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>2.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2675</td>\n",
       "      <td>2.071500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>2.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2725</td>\n",
       "      <td>2.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>1.939500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2775</td>\n",
       "      <td>2.016100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.047500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2825</td>\n",
       "      <td>2.078100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>1.998600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2875</td>\n",
       "      <td>2.081700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>2.003700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2925</td>\n",
       "      <td>2.130800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>2.034400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2975</td>\n",
       "      <td>2.107400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3025</td>\n",
       "      <td>2.083600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>1.986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3075</td>\n",
       "      <td>2.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>2.047300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3125</td>\n",
       "      <td>2.088400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>2.052500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3175</td>\n",
       "      <td>2.141700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.941700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3225</td>\n",
       "      <td>2.150100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>1.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3275</td>\n",
       "      <td>2.080400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>1.950600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3325</td>\n",
       "      <td>2.068900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>2.033200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3375</td>\n",
       "      <td>2.154600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>2.043800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3425</td>\n",
       "      <td>2.102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>2.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3475</td>\n",
       "      <td>2.131200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.973000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3525</td>\n",
       "      <td>2.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>1.975200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3575</td>\n",
       "      <td>2.085700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.994600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3625</td>\n",
       "      <td>2.126300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>2.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3675</td>\n",
       "      <td>2.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>2.035600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3725</td>\n",
       "      <td>2.108100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>2.051100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3775</td>\n",
       "      <td>2.056800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.967500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3825</td>\n",
       "      <td>2.123900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>1.977200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3875</td>\n",
       "      <td>2.156900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>2.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3925</td>\n",
       "      <td>2.044900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>1.930200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3975</td>\n",
       "      <td>2.080500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.935000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4025</td>\n",
       "      <td>2.090400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>2.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4075</td>\n",
       "      <td>2.092000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>2.014300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4125</td>\n",
       "      <td>2.099500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>2.027200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4175</td>\n",
       "      <td>2.111400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>2.032600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4225</td>\n",
       "      <td>2.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>2.054300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4275</td>\n",
       "      <td>2.067200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>1.917300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4325</td>\n",
       "      <td>2.083600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>1.964900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4375</td>\n",
       "      <td>2.041100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>1.985600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4425</td>\n",
       "      <td>2.094200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>1.992300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4475</td>\n",
       "      <td>2.124800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.032700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4525</td>\n",
       "      <td>2.081400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>2.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4575</td>\n",
       "      <td>2.123300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>2.062700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4625</td>\n",
       "      <td>2.071300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>1.994000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4675</td>\n",
       "      <td>2.100700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>1.880200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4725</td>\n",
       "      <td>2.090900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>1.989100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4775</td>\n",
       "      <td>2.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>1.945200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4825</td>\n",
       "      <td>2.070200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>2.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4875</td>\n",
       "      <td>2.108700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>1.932500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4925</td>\n",
       "      <td>2.069500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>1.985400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4975</td>\n",
       "      <td>2.080800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.991700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5025</td>\n",
       "      <td>2.059300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5050</td>\n",
       "      <td>1.976700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5075</td>\n",
       "      <td>2.054400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>2.048400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5125</td>\n",
       "      <td>2.077500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5150</td>\n",
       "      <td>2.077800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5175</td>\n",
       "      <td>2.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>1.944200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5225</td>\n",
       "      <td>2.094600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>1.948800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5275</td>\n",
       "      <td>2.014500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>1.951800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5325</td>\n",
       "      <td>2.106800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5350</td>\n",
       "      <td>2.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5375</td>\n",
       "      <td>2.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>2.016100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5425</td>\n",
       "      <td>2.056400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5450</td>\n",
       "      <td>1.932200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5475</td>\n",
       "      <td>2.111600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.948800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5525</td>\n",
       "      <td>2.078300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5550</td>\n",
       "      <td>1.916300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5575</td>\n",
       "      <td>2.100500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>1.967100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5625</td>\n",
       "      <td>2.042700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5650</td>\n",
       "      <td>1.928500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5675</td>\n",
       "      <td>2.011900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>2.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5725</td>\n",
       "      <td>2.024600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5750</td>\n",
       "      <td>2.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5775</td>\n",
       "      <td>2.106600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>2.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5825</td>\n",
       "      <td>2.041400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5850</td>\n",
       "      <td>1.996800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5875</td>\n",
       "      <td>2.109600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>1.997800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5925</td>\n",
       "      <td>2.046300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5950</td>\n",
       "      <td>1.976900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5975</td>\n",
       "      <td>2.069300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.017500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6025</td>\n",
       "      <td>2.042700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6050</td>\n",
       "      <td>1.965900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6075</td>\n",
       "      <td>2.079200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>1.975100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6125</td>\n",
       "      <td>2.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6150</td>\n",
       "      <td>1.994900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6175</td>\n",
       "      <td>2.092100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>2.027800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6225</td>\n",
       "      <td>1.983700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6250</td>\n",
       "      <td>1.934700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6275</td>\n",
       "      <td>2.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>2.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6325</td>\n",
       "      <td>2.110100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6350</td>\n",
       "      <td>2.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6375</td>\n",
       "      <td>2.074400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>1.986500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6425</td>\n",
       "      <td>2.126500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6450</td>\n",
       "      <td>1.952100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6475</td>\n",
       "      <td>2.116800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.908800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6525</td>\n",
       "      <td>2.070500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6550</td>\n",
       "      <td>2.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6575</td>\n",
       "      <td>2.123800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>1.954900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6625</td>\n",
       "      <td>2.060700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6650</td>\n",
       "      <td>1.921600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6675</td>\n",
       "      <td>2.095900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>2.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6725</td>\n",
       "      <td>2.140600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6750</td>\n",
       "      <td>1.881800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6775</td>\n",
       "      <td>2.121400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>1.978300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6825</td>\n",
       "      <td>2.138600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6850</td>\n",
       "      <td>1.971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6875</td>\n",
       "      <td>2.096400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>1.964500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6925</td>\n",
       "      <td>2.131000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6950</td>\n",
       "      <td>1.983500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6975</td>\n",
       "      <td>2.067900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.908200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7025</td>\n",
       "      <td>2.133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7050</td>\n",
       "      <td>2.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7075</td>\n",
       "      <td>2.078300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>1.940900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7125</td>\n",
       "      <td>2.109700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7150</td>\n",
       "      <td>2.031900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7175</td>\n",
       "      <td>2.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>1.947100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7225</td>\n",
       "      <td>2.024100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7250</td>\n",
       "      <td>2.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7275</td>\n",
       "      <td>2.118200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>1.933500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7325</td>\n",
       "      <td>2.092100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7350</td>\n",
       "      <td>1.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7375</td>\n",
       "      <td>2.090900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>2.035400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7425</td>\n",
       "      <td>2.083400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7450</td>\n",
       "      <td>2.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7475</td>\n",
       "      <td>2.105900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>2.059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7525</td>\n",
       "      <td>2.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7550</td>\n",
       "      <td>1.983200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7575</td>\n",
       "      <td>2.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>2.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7625</td>\n",
       "      <td>1.986500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7650</td>\n",
       "      <td>2.026100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7675</td>\n",
       "      <td>2.089400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>1.964500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7725</td>\n",
       "      <td>2.097300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7750</td>\n",
       "      <td>2.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7775</td>\n",
       "      <td>2.060100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>1.936900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7825</td>\n",
       "      <td>2.065600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7850</td>\n",
       "      <td>1.993300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7875</td>\n",
       "      <td>2.084800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>1.982900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7925</td>\n",
       "      <td>2.085700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7950</td>\n",
       "      <td>1.962500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7975</td>\n",
       "      <td>2.135900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.964700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8025</td>\n",
       "      <td>2.129400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8050</td>\n",
       "      <td>1.988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8075</td>\n",
       "      <td>2.097600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>1.992900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8125</td>\n",
       "      <td>2.094200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8150</td>\n",
       "      <td>1.976300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8175</td>\n",
       "      <td>2.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>1.994500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8225</td>\n",
       "      <td>2.067000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8250</td>\n",
       "      <td>1.954700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8275</td>\n",
       "      <td>2.066300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>1.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8325</td>\n",
       "      <td>2.140800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8350</td>\n",
       "      <td>2.031600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8375</td>\n",
       "      <td>2.046500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>1.953700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8425</td>\n",
       "      <td>2.140400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8450</td>\n",
       "      <td>2.020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8475</td>\n",
       "      <td>2.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>2.039900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8525</td>\n",
       "      <td>2.080900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8550</td>\n",
       "      <td>1.965700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8575</td>\n",
       "      <td>2.090200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>2.050200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8625</td>\n",
       "      <td>2.119900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8650</td>\n",
       "      <td>2.010100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8675</td>\n",
       "      <td>2.062800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>2.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8725</td>\n",
       "      <td>2.092300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8750</td>\n",
       "      <td>1.903900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8775</td>\n",
       "      <td>2.084800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>1.940200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8825</td>\n",
       "      <td>2.122200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8850</td>\n",
       "      <td>1.959200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8875</td>\n",
       "      <td>2.101300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>2.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8925</td>\n",
       "      <td>2.054300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8950</td>\n",
       "      <td>2.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8975</td>\n",
       "      <td>2.082700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.975700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9025</td>\n",
       "      <td>2.034400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9050</td>\n",
       "      <td>1.887000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9075</td>\n",
       "      <td>2.185600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>1.998300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9125</td>\n",
       "      <td>2.075900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9150</td>\n",
       "      <td>2.052400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9175</td>\n",
       "      <td>2.105600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>2.008200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9225</td>\n",
       "      <td>1.997800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9250</td>\n",
       "      <td>1.908400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9275</td>\n",
       "      <td>2.023900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>1.987000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9325</td>\n",
       "      <td>2.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9350</td>\n",
       "      <td>1.976900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9375</td>\n",
       "      <td>2.058700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>1.979400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9425</td>\n",
       "      <td>2.060800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9450</td>\n",
       "      <td>1.983600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9475</td>\n",
       "      <td>2.067700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.995200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9525</td>\n",
       "      <td>2.060700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9550</td>\n",
       "      <td>1.891800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9575</td>\n",
       "      <td>2.086500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>2.018500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9625</td>\n",
       "      <td>2.095900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9650</td>\n",
       "      <td>1.903900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9675</td>\n",
       "      <td>2.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>1.959500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9711, training_loss=2.046107460205028, metrics={'train_runtime': 14502.4488, 'train_samples_per_second': 1.339, 'train_steps_per_second': 0.67, 'total_flos': 2.1255014040639898e+17, 'train_loss': 2.046107460205028, 'epoch': 1.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################\n",
    "### Fine-Tune Model ###\n",
    "#######################\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f67ce6c-0fda-47c1-b0d0-b42b5b026edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tuned-llama-3.1-8b/tokenizer_config.json',\n",
       " 'tuned-llama-3.1-8b/special_tokens_map.json',\n",
       " 'tuned-llama-3.1-8b/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################\n",
    "### Save Model ###\n",
    "##################\n",
    "new_model = \"tuned-llama-3.1-8b\"\n",
    "trainer.model.save_pretrained(new_model)\n",
    "trainer.processing_class.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e15b8b74-1d4f-41ac-a6fd-1ee7a23cd514",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is a large language model?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[1;32m      7\u001b[0m   task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      8\u001b[0m   model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/zhy542/tuned-llama-3.1-8b\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m----> 9\u001b[0m   tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, \n\u001b[1;32m     10\u001b[0m   max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m     11\u001b[0m   device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m result \u001b[38;5;241m=\u001b[39m pipe(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[s][INST] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [/INST]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "#################\n",
    "### Try Model ###\n",
    "#################\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "prompt = \"What is a large language model?\"\n",
    "pipe = pipeline(\n",
    "  task=\"text-generation\", \n",
    "  model=\"/home/zhy542/tuned-llama-3.1-8b\", \n",
    "  tokenizer=tokenizer, \n",
    "  max_length=200,\n",
    "  device = 'cpu'\n",
    ")\n",
    "result = pipe(f\"[s][INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c09cd3-5cd0-4905-b17a-f4c158c694fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "### Evaluate Model ###\n",
    "#################\n",
    "\n",
    "\n",
    "# Sample ground truth (reference) and model-generated (prediction) headlines\n",
    "references = [\n",
    "    \"Breaking news: Major earthquake hits California\",\n",
    "    \"Scientists discover a new species of deep-sea fish\"\n",
    "]\n",
    "predictions = [\n",
    "    \"Major earthquake strikes California\",\n",
    "    \"New deep-sea fish species discovered\"\n",
    "]\n",
    "\n",
    "# Accuracy\n",
    "def calculate_accuracy(references, predictions):\n",
    "    return np.mean([ref == pred for ref, pred in zip(references, predictions)])\n",
    "\n",
    "# ROUGE Scores\n",
    "def calculate_rouge(references, predictions):\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "    scores = [scorer.score(ref, pred) for ref, pred in zip(references, predictions)]\n",
    "    averaged_scores = {\n",
    "        metric: np.mean([score[metric].fmeasure for score in scores])\n",
    "        for metric in [\"rouge1\", \"rouge2\", \"rougeL\"]\n",
    "    }\n",
    "    return averaged_scores\n",
    "\n",
    "# BERTScore\n",
    "def calculate_bertscore(references, predictions):\n",
    "    P, R, F1 = bert_score(predictions, references, lang=\"en\", verbose=True)\n",
    "    return {\n",
    "        \"precision\": np.mean(P),\n",
    "        \"recall\": np.mean(R),\n",
    "        \"f1\": np.mean(F1)\n",
    "    }\n",
    "\n",
    "# MoverScore\n",
    "def calculate_moverscore(references, predictions):\n",
    "    idf_dict_ref = get_idf_dict(references)\n",
    "    idf_dict_pred = get_idf_dict(predictions)\n",
    "    scores = word_mover_score(references, predictions, idf_dict_ref, idf_dict_pred,\n",
    "                              stop_words=[], n_gram=1, remove_subwords=True, batch_size=8)\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = calculate_accuracy(references, predictions)\n",
    "rouge_scores = calculate_rouge(references, predictions)\n",
    "bertscore_results = calculate_bertscore(references, predictions)\n",
    "moverscore_result = calculate_moverscore(references, predictions)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"ROUGE Scores: {rouge_scores}\")\n",
    "print(f\"BERTScore: {bertscore_results}\")\n",
    "print(f\"MoverScore: {moverscore_result:.2f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

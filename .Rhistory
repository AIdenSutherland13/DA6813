bottom = 'Figure X.X: Boxplots of Numerical Values')
##Categorical Variables
ggplot(bbbc_full) +
facet_wrap(~Choice) +
labs(caption = "Figure X.X:") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), plot.caption = element_text(hjust = 0.5)) +
geom_bar(aes(x = Gender))
#Correlation Plot
combined = rbind(train, test)
corrplot::corrplot(cor(combined[,c(4:12)]), method = c("number")) #First and last purchased have pretty high correlation
#Normalize data
train = scale(train[,c(4:12)]) #normalize numeric data
train = cbind(BBBC_train[,2:3], train) #combine factor data with normalized data and leaving out the index column ("observation")
train[fac_vars] = lapply(train[fac_vars],as.factor)
str(train)
test = scale(test[,c(4:12)]) #normalize numeric data
test = cbind(BBBC_test[,2:3], test) #combine factor data with normalized data and leaving out the index column ("observation")
test[fac_vars] = lapply(test[fac_vars],as.factor)
str(test) #"test" data set should be used on predictions
### BALANCE DATA
set.seed(123)
train_y = train %>% filter(Choice ==1)
train_n = train %>% filter(Choice ==0)
sample_y = sample_n(train_n, nrow(train_y))
train_bal = rbind(train_y, sample_y) #"train_bal" is final trained data set to be used on models
plot(train_bal$Choice)
#Balancing test test data set not needed
#test_y = test %>% filter(Choice ==1)
#test_n = test %>% filter(Choice ==0)
#sample_test_y = sample_n(test_n, nrow(test_y))
#test_bal = rbind(test_y, sample_test_y)
#plot(test_bal$Choice)
### Linear Model
## LR Model
lr_train = train_bal
lr_train$Choice <- as.numeric(as.character(lr_train$Choice))  # it's a factor stored as numbers
lr_train$Gender = as.numeric(as.character(lr_train$Gender))
lr_test = test
lr_test$Choice = as.numeric(as.character(lr_test$Choice))
lr_test$Gender = as.numeric(as.character(lr_test$Gender))
m1 = lm(Choice ~., data = lr_train)
vif(m1) #last_purchase high vif
m2 = lm(Choice ~ . -Last_purchase, data = lr_train)
vif(m2) #first_purchase vif > 5
m3 <- lm(Choice ~ Gender + Amount_purchased + Frequency + P_Child + P_Youth + P_Cook + P_DIY + P_Art,
data = lr_train)
vif(m3) #vifs look good
summary(m3) #P_Youth not significant
m4 = lm(Choice ~ Gender + Amount_purchased + Frequency + P_Child + P_Cook + P_DIY + P_Art,
data = lr_train)
summary(m4)
#P_Cook became significant after training the model on balanced training data set
#m5 = lm(Choice ~ Gender + Amount_purchased + Frequency + P_Child + P_DIY + P_Art,
#data = train)
#summary(m5)
predictions = predict(m4, newdata = lr_test, type = "response")
#Measures
mse = mean((lr_test$Choice - predictions)^2)
mae = mean(abs(lr_test$Choice - predictions))
me = mean(lr_test$Choice - predictions)
mape =  mean(abs(lr_test$Choice - predictions)/lr_test$Choice)*100
#Multi Collinearity
log.model = glm(Choice ~ . , data = train_bal, family = binomial)
vif(log.model)
log.model2 = glm(Choice ~ . -Last_purchase , data = train_bal, family = binomial) #Remove last_purchased
vif(log.model2)
log.model3 = glm(Choice ~ Gender + Amount_purchased + Frequency + P_Child + P_Youth + P_Cook + P_DIY
+ P_Art , data = train_bal, family = binomial) #Remove first_purchased
vif(log.model3) #all vifs<5
#Logistic model
summary(log.model3) #P_Youth not significant
log.model4 = glm(Choice ~ Gender + Amount_purchased + Frequency + P_Child + P_Cook + P_DIY
+ P_Art , data = train_bal, family = binomial) #Remove P_Youth
summary(log.model4)
#Predictions
test$PredProb = predict.glm(log.model4, newdata = test, type = "response")
test$PredSur = ifelse(test$PredProb >= 0.54, 1, 0) # Create new variable converting probabilities to 1s and 0s
# "Confusion Matrix" to get accuracy of the model prediction
caret::confusionMatrix(as.factor(test$PredSur), as.factor(test$Choice),positive = "1" ) #Comparing observed to predicted
### Adding SVM Model (with balanced data and optimal predictors) ###
# We'll scale both the training and testing data (except for the target variable)
train_scaled <- train_bal
test_scaled <- test
# Scale the numeric columns in the training and test sets
test_scaled$Choice <- as.factor(test_scaled$Choice)
train_scaled$Choice <- as.factor(train_scaled$Choice)
numeric_cols <- sapply(train_scaled, is.numeric)
train_scaled[numeric_cols] <- scale(train_scaled[numeric_cols])
test_scaled[numeric_cols] <- scale(test_scaled[numeric_cols])
# SVM Model with Grid Search for Hyper parameter Tuning
# Define tuning grid for cost and gamma (for radial kernel)
tune_grid <- expand.grid(C = c(0.01, 0.1, 1, 10, 100),
sigma = c(0.001, 0.01, 0.1, 1))
# Tuning Radial Basis Function (RBF) kernel SVM
set.seed(123)
svm_tune <- tune(svm, Choice ~ ., data = train_scaled,
kernel = "radial",
ranges = list(cost = tune_grid$C, gamma = tune_grid$sigma),
scale = FALSE)  # Don't scale inside the SVM function, we've already done that
# Best model based on cross-validation
best_model <- svm_tune$best.model
print(svm_tune)
# Test the tuned SVM model
pred_svm <- predict(best_model, newdata = test_scaled)
confusionMatrix(pred_svm, test_scaled$Choice)
# Testing Other Kernels
# Linear Kernel
set.seed(123)
svm_linear <- svm(Choice ~ ., data = train_scaled,
kernel = "linear",
cost = best_model$cost,
scale = FALSE)
pred_linear <- predict(svm_linear, newdata = test_scaled)
confusionMatrix(pred_linear, test_scaled$Choice)
# Polynomial Kernel (degree 3)
set.seed(123)
svm_poly <- svm(Choice ~ ., data = train_scaled,
kernel = "polynomial",
cost = best_model$cost,
degree = 3,
scale = FALSE)
pred_poly <- predict(svm_poly, newdata = test_scaled)
confusionMatrix(pred_poly, test_scaled$Choice)
# Compare accuracy across different kernels
linear_acc <- sum(pred_linear == test_scaled$Choice) / nrow(test_scaled)
rbf_acc <- sum(pred_svm == test_scaled$Choice) / nrow(test_scaled)
poly_acc <- sum(pred_poly == test_scaled$Choice) / nrow(test_scaled)
cat("Linear Kernel Accuracy: ", linear_acc, "\n")
cat("RBF Kernel Accuracy: ", rbf_acc, "\n")
cat("Polynomial Kernel Accuracy: ", poly_acc, "\n")
### LDA Model ###
# LDA Feature Selection
rand_f.model = randomForest::randomForest(Choice ~ Gender + Amount_purchased + Frequency + P_Child + P_Youth + P_Cook + P_DIY + P_Art, data = train_bal)
varImpPlot(rand_f.model,
sort = T,
n.var = 10,
main = "Figure 3. Variable Important plot")
# LDA Model
LDA.model.full = lda(Choice ~ Gender + Amount_purchased + Frequency + P_Child + P_Youth + P_Cook + P_DIY + P_Art, data = train_bal)
LDA.model.trim = lda(Choice ~ Amount_purchased + Frequency + P_Art, data = train_bal)
# LDA Predictions
LDA.preds.full = predict(LDA.model.full, test, probability = TRUE)
LDA.preds.trim = predict(LDA.model.trim, test, probability = TRUE)
# Partition Plot
partimat(Choice ~ Amount_purchased + Frequency + P_Art, data = train_bal, method = "lda")
# Model Performance
## All Predictors
caret::confusionMatrix(as.factor(LDA.preds.full$class), test$Choice, positive = '1')
## Trimmed Predictors
caret::confusionMatrix(as.factor(LDA.preds.trim$class), test$Choice, positive = '1')
##### Predicting Profits #####
#Calc profit per book
book_cost = 15*1.45 #each book costs $15 plus 45% overhead
book_profit = 31.95-book_cost #each book is sold for $31.95
#If sending mailings to entire list
total_list = 50000 #list of 50,000 customers to mail ad to
total_cost = 0.65*total_list #cost to mail entire list an ad
#According to case study prompt, 9.03% of mailings resulted in an order
total_profit = 0.0903*total_list*book_profit-total_cost
#If using logistic regression model to selectively send mailings
#predicted (599+146)/(2300)=32.4% would purchase a book with only 146/(599+146) actually buying the book (19.6%)
model_list = total_list*0.324 #Number of customers to send mailings to
model_cost = 0.65*model_list #$0.65/mailing
model_profit = 0.196*model_list*book_profit-model_cost
#If using LDA model to selectively send mailings
#predicted (751 + 150) / 2300 = 39.17% would purchase a book with only 150 / (751 + 150) of those customers actually buying the book (16.6%)
model_list_lda = total_list * ((751 + 150) / 2300)
model_cost_lda = 0.65 * model_list_lda
model_profit_lda = (150 / (751 + 150)) * model_list_lda * book_profit - model_cost_lda
# If using the SVM linear model to selectively send mailings
#Summary of results
cat("Profit if mailed entire list: $", total_profit, "\n")
cat("Profit if list generated by Logistic model: $", model_profit, "\n")
cat("% Increase in Profits: ", (model_profit-total_profit)*100/total_profit, "%", "\n")
cat("Profit if list generated by LSA model: $", model_profit_lda, '\n')
cat('% increase in Profits with LDA model: ', (model_profit_lda - total_profit) * 100 / total_profit, '%', '\n')
# If using the SVM linear model to selectively send mailings
predicted_response_rate_svm <- 0.6078 # Sensitivity from the SVM linear kernel model
# Predicting the number of customers likely to purchase
model_list_svm <- total_list * predicted_response_rate_svm # Number of customers to send mailings to
model_cost_svm <- 0.65 * model_list_svm # $0.65 per mailing
# Assuming a purchase conversion rate based on the actual purchases made
actual_purchase_conversion_rate <- 0.196 # Conversion rate based on the logistic regression results
model_profit_svm <- actual_purchase_conversion_rate * model_list_svm * book_profit - model_cost_svm
#Summary of results
cat("Profit if mailed entire list: $", total_profit, "\n")
cat("Profit if list generated by Logistic model: $", model_profit, "\n")
cat("% Increase in Profits: ", (model_profit-total_profit)*100/total_profit, "%", "\n")
cat("Profit if list generated by LSA model: $", model_profit_lda, '\n')
cat('% increase in Profits with LDA model: ', (model_profit_lda - total_profit) * 100 / total_profit, '%', '\n')
cat("Profit if list generated by SVM linear model: $", model_profit_svm, "\n")
cat("% Increase in Profits: ", (model_profit_svm - total_profit) * 100 / total_profit, "%", "\n")
##### Predicting Profits #####
#Calc profit per book
book_cost = 15*1.45 #each book costs $15 plus 45% overhead
book_profit = 31.95-book_cost #each book is sold for $31.95
#If sending mailings to entire list
total_list = 50000 #list of 50,000 customers to mail ad to
total_cost = 0.65*total_list #cost to mail entire list an ad
#According to case study prompt, 9.03% of mailings resulted in an order
total_profit = 0.0903*total_list*book_profit-total_cost
#If using logistic regression model to selectively send mailings
#predicted (599+146)/(2300)=32.4% would purchase a book with only 146/(599+146) actually buying the book (19.6%)
model_list = total_list*0.324 #Number of customers to send mailings to
model_cost = 0.65*model_list #$0.65/mailing
model_profit = 0.196*model_list*book_profit-model_cost
#If using LDA model to selectively send mailings
#predicted (751 + 150) / 2300 = 39.17% would purchase a book with only 150 / (751 + 150) of those customers actually buying the book (16.6%)
model_list_lda = total_list * ((751 + 150) / 2300)
model_cost_lda = 0.65 * model_list_lda
model_profit_lda = (150 / (751 + 150)) * model_list_lda * book_profit - model_cost_lda
# If using the SVM linear model to selectively send mailings
predicted_response_rate_svm <- 0.6078 # Sensitivity from the SVM linear kernel model
# Predicting the number of customers likely to purchase
model_list_svm <- total_list * predicted_response_rate_svm # Number of customers to send mailings to
model_cost_svm <- 0.65 * model_list_svm # $0.65 per mailing
# Assuming a purchase conversion rate based on the actual purchases made
actual_purchase_conversion_rate <- 0.196 # Conversion rate based on the logistic regression results
model_profit_svm <- actual_purchase_conversion_rate * model_list_svm * book_profit - model_cost_svm
#Summary of results
cat("Profit if mailed entire list: $", total_profit, "\n")
cat("Profit if list generated by Logistic model: $", model_profit, "\n")
cat("% Increase in Profits: ", (model_profit-total_profit)*100/total_profit, "%", "\n")
cat("Profit if list generated by LSA model: $", model_profit_lda, '\n')
cat('% increase in Profits with LDA model: ', (model_profit_lda - total_profit) * 100 / total_profit, '%', '\n')
cat("Profit if list generated by SVM linear model: $", model_profit_svm, "\n")
cat("% Increase in Profits: ", (model_profit_svm - total_profit) * 100 / total_profit, "%", "\n")
##### Predicting Profits #####
#Calc profit per book
book_cost = 15*1.45 #each book costs $15 plus 45% overhead
book_profit = 31.95-book_cost #each book is sold for $31.95
#If sending mailings to entire list
total_list = 50000 #list of 50,000 customers to mail ad to
total_cost = 0.65*total_list #cost to mail entire list an ad
#According to case study prompt, 9.03% of mailings resulted in an order
total_profit = 0.0903*total_list*book_profit-total_cost
#If using logistic regression model to selectively send mailings
#predicted (599+146)/(2300)=32.4% would purchase a book with only 146/(599+146) actually buying the book (19.6%)
model_list = total_list*0.324 #Number of customers to send mailings to
model_cost = 0.65*model_list #$0.65/mailing
model_profit = 0.196*model_list*book_profit-model_cost
#If using LDA model to selectively send mailings
#predicted (751 + 150) / 2300 = 39.17% would purchase a book with only 150 / (751 + 150) of those customers actually buying the book (16.6%)
model_list_lda = total_list * ((751 + 150) / 2300)
model_cost_lda = 0.65 * model_list_lda
model_profit_lda = (150 / (751 + 150)) * model_list_lda * book_profit - model_cost_lda
# If using the SVM linear model to selectively send mailings
predicted_response_rate_svm <- 0.6078 # Sensitivity from the SVM linear kernel model
# Predicting the number of customers likely to purchase
model_list_svm <- total_list * predicted_response_rate_svm # Number of customers to send mailings to
model_cost_svm <- 0.65 * model_list_svm # $0.65 per mailing
# Assuming a purchase conversion rate based on the actual purchases made
actual_purchase_conversion_rate <- 0.196 # Conversion rate based on the logistic regression results
model_profit_svm <- actual_purchase_conversion_rate * model_list_svm * book_profit - model_cost_svm
#Summary of results
cat("Profit if mailed entire list: $", total_profit, "\n")
cat("Profit if list generated by Logistic model: $", model_profit, "\n")
cat("% Increase in Profits: ", (model_profit-total_profit)*100/total_profit, "%", "\n")
cat("Profit if list generated by LSA model: $", model_profit_lda, '\n')
cat('% increase in Profits with LDA model: ', (model_profit_lda - total_profit) * 100 / total_profit, '%', '\n')
cat("Profit if list generated by SVM linear model: $", model_profit_svm, "\n")
cat("% Increase in Profits: ", (model_profit_svm - total_profit) * 100 / total_profit, "%", "\n")
##### Predicting Profits #####
#Calc profit per book
book_cost = 15*1.45 #each book costs $15 plus 45% overhead
book_profit = 31.95-book_cost #each book is sold for $31.95
#If sending mailings to entire list
total_list = 50000 #list of 50,000 customers to mail ad to
total_cost = 0.65*total_list #cost to mail entire list an ad
#According to case study prompt, 9.03% of mailings resulted in an order
total_profit = 0.0903*total_list*book_profit-total_cost
#If using logistic regression model to selectively send mailings
#predicted (599+146)/(2300)=32.4% would purchase a book with only 146/(599+146) actually buying the book (19.6%)
model_list = total_list*0.324 #Number of customers to send mailings to
model_cost = 0.65*model_list #$0.65/mailing
model_profit = 0.196*model_list*book_profit-model_cost
#If using LDA model to selectively send mailings
#predicted (751 + 150) / 2300 = 39.17% would purchase a book with only 150 / (751 + 150) of those customers actually buying the book (16.6%)
model_list_lda = total_list * ((751 + 150) / 2300)
model_cost_lda = 0.65 * model_list_lda
model_profit_lda = (150 / (751 + 150)) * model_list_lda * book_profit - model_cost_lda
# If using the SVM linear model to selectively send mailings
predicted_response_rate_svm <- 0.6078 # Sensitivity from the SVM linear kernel model
# Predicting the number of customers likely to purchase
model_list_svm <- total_list * predicted_response_rate_svm # Number of customers to send mailings to
model_cost_svm <- 0.65 * model_list_svm # $0.65 per mailing
# Assuming a purchase conversion rate based on the actual purchases made
actual_purchase_conversion_rate <- 0.196 # Conversion rate based on the logistic regression results
model_profit_svm <- actual_purchase_conversion_rate * model_list_svm * book_profit - model_cost_svm
#Summary of results
cat("Profit if mailed entire list: $", total_profit, "\n")
cat("Profit if list generated by Logistic model: $", model_profit, "\n")
cat("% Increase in Profits: ", (model_profit-total_profit)*100/total_profit, "%", "\n")
cat("Profit if list generated by LSA model: $", model_profit_lda, '\n')
cat('% increase in Profits with LDA model: ', (model_profit_lda - total_profit) * 100 / total_profit, '%', '\n')
cat("Profit if list generated by SVM linear model: $", model_profit_svm, "\n")
cat("% Increase in Profits: ", (model_profit_svm - total_profit) * 100 / total_profit, "%", "\n")
svm_linear <- svm(Choice ~ ., data = train_scaled,
kernel = "linear",
cost = best_model$cost,
scale = FALSE)
pred_linear <- predict(svm_linear, newdata = test_scaled)
confusionMatrix(pred_linear, test_scaled$Choice)
pacman::p_load(caret, lattice, tidyverse, gam, logistf, MASS, car, corrplot, gridExtra, ROCR, RCurl, randomForest, readr, readxl, e1071, klaR)
##### Data Set ######
dow_raw = as.data.frame(read.csv(text = getURL('https://raw.githubusercontent.com/btj5z2/DA6813/main/dow_jones_index.data'), header = TRUE))
##### Copy of Data Set for Model ######
dow = dow_raw
### Review Details of Data Set ###
str(dow)
# Many numeric values were read in as strings
# Convert these values to numeric data types
num_vars = c('open', 'high', 'low', 'close', 'next_weeks_open', 'next_weeks_close')
dow[num_vars] = lapply(dow[num_vars], gsub, pattern = '[\\$,]', replacement = '')
dow[num_vars] = lapply(dow[num_vars], as.numeric)
# Convert 'date' column to date type
dow$date = as.Date(dow$date, '%m/%d/%Y')
### Review column details to validate changes ###
str(dow)
### Identify columns with NA's ###
names(which(colSums(is.na(dow)) > 0))
paste('Total NAs in percent_change_volume_over_last_wk: ', sum(is.na(dow$percent_change_volume_over_last_wk)))
paste('Total NAs in previous_weeks_volume: ', sum(is.na(dow$previous_weeks_volume)))
## Number of columns where percent_change_volume_over_last_wk is NA while previous_weeks_volume is not
dow %>%
tally(is.na(dow$percent_change_volume_over_last_wk) & !is.na(dow$previous_weeks_volume))
## Number of columns where both percent_change_volume_over_last_wk and previous_weeks_volume are NA
dow %>%
tally(is.na(dow$percent_change_volume_over_last_wk) & is.na(dow$previous_weeks_volume))
# percent_change_volume_over_last_wk and previous_weeks_volume are both either NA or not NA
# this makes sense because the percent change would have to be null if there was no previous week volume
# Show which dates have NA values for previous week
unique(dow$date[is.na(dow$percent_change_volume_over_last_wk)])
# Count number of entries of the date that includes NA values
table(dow$date[dow$date=="2011-01-07"])
# Check for earliest date in dataset
min(dow$date)
# All entries on 1/7/2011 have NA values for prior week.
# This date is the earliest date in the dataset, so these values being for previous week can be expected
# Any time series analysis over the change in volumes, should omit these rows
### Plot of percent price change over time
dow %>%
ggplot(aes(x = date, y = percent_change_price, group = stock, color = stock)) +
geom_line()
pacman::p_load(caret, lattice, tidyverse, gam, logistf, MASS, car, corrplot, gridExtra, ROCR, RCurl, randomForest, readr, readxl, e1071, klaR)
##### Data Set ######
dow_raw = as.data.frame(read.csv(text = getURL('https://raw.githubusercontent.com/btj5z2/DA6813/main/dow_jones_index.data'), header = TRUE))
##### Copy of Data Set for Model ######
dow = dow_raw
### Review Details of Data Set ###
str(dow)
# Many numeric values were read in as strings
# Convert these values to numeric data types
num_vars = c('open', 'high', 'low', 'close', 'next_weeks_open', 'next_weeks_close')
dow[num_vars] = lapply(dow[num_vars], gsub, pattern = '[\\$,]', replacement = '')
dow[num_vars] = lapply(dow[num_vars], as.numeric)
# Convert 'date' column to date type
dow$date = as.Date(dow$date, '%m/%d/%Y')
### Review column details to validate changes ###
str(dow)
### Identify columns with NA's ###
names(which(colSums(is.na(dow)) > 0))
paste('Total NAs in percent_change_volume_over_last_wk: ', sum(is.na(dow$percent_change_volume_over_last_wk)))
paste('Total NAs in previous_weeks_volume: ', sum(is.na(dow$previous_weeks_volume)))
## Number of columns where percent_change_volume_over_last_wk is NA while previous_weeks_volume is not
dow %>%
tally(is.na(dow$percent_change_volume_over_last_wk) & !is.na(dow$previous_weeks_volume))
## Number of columns where both percent_change_volume_over_last_wk and previous_weeks_volume are NA
dow %>%
tally(is.na(dow$percent_change_volume_over_last_wk) & is.na(dow$previous_weeks_volume))
# percent_change_volume_over_last_wk and previous_weeks_volume are both either NA or not NA
# this makes sense because the percent change would have to be null if there was no previous week volume
# Show which dates have NA values for previous week
unique(dow$date[is.na(dow$percent_change_volume_over_last_wk)])
# Count number of entries of the date that includes NA values
table(dow$date[dow$date=="2011-01-07"])
# Check for earliest date in dataset
min(dow$date)
# All entries on 1/7/2011 have NA values for prior week.
# This date is the earliest date in the dataset, so these values being for previous week can be expected
# Any time series analysis over the change in volumes, should omit these rows
#Remove NA values
dow = na.omit(dow)
### Plot of percent price change over time
dow %>%
ggplot(aes(x = date, y = percent_change_price, group = stock, color = stock)) +
geom_line()
#Correlation Plot
corrplot::corrplot(cor(dow[,-c(2:3)]), method = c("number")) #Quite a few variables with high correlation
#Multi Collinearity
lin.model = lm(percent_change_next_weeks_price ~ . , data = dow)
vif(lin.model) #Remove close
lin.model2 = lm(percent_change_next_weeks_price ~ . -close , data = dow)
vif(lin.model2) #Remove high
lin.model3 = lm(percent_change_next_weeks_price ~ . -close -high , data = dow)
vif(lin.model3) #Remove next_weeks_open
lin.model4 = lm(percent_change_next_weeks_price ~ . -close -high -next_weeks_open, data = dow)
vif(lin.model4) #Remove low
lin.model5 = lm(percent_change_next_weeks_price ~ . -close -high -next_weeks_open -low, data = dow)
vif(lin.model5) #Remove open
lin.model5 = lm(percent_change_next_weeks_price ~ . -close -high -next_weeks_open -low -open, data = dow)
vif(lin.model5) #Remove next_weeks_close
lin.model6 = lm(percent_change_next_weeks_price ~ . -close -high -next_weeks_open -low -open -next_weeks_close, data = dow)
vif(lin.model6) #Remove percent_return_next_dividend
lin.model7 = lm(percent_change_next_weeks_price ~ . -close -high -next_weeks_open -low -open -next_weeks_close -percent_return_next_dividend, data = dow)
vif(lin.model7) #all vifs<5
#Remove variables from data set
dow = subset(dow, select = -c(close, high, next_weeks_open, low, open, next_weeks_close, percent_return_next_dividend))
#Box plots of variables
grid.arrange(ggplot(dow, aes(volume)) + geom_boxplot(),
ggplot(dow, aes(percent_change_price)) + geom_boxplot(),
ggplot(dow, aes(percent_change_volume_over_last_wk)) + geom_boxplot(),
ggplot(dow, aes(previous_weeks_volume)) + geom_boxplot(),
ggplot(dow, aes(percent_change_next_weeks_price)) + geom_boxplot(),
ggplot(dow, aes(days_to_next_dividend)) + geom_boxplot(),
ncol = 2,
bottom = 'Figure X.X: Boxplots of Numerical Values')
#Numerical data is pretty skewed. Likely worth normalizing.
#install.packages("bestNormalize")
library(bestNormalize)
dow_norm = lapply(dow[,c(4:9)], yeojohnson) #normalize numeric data
#scale function just changed the scale, it was still skewed. log and sqrt gave errors to ended up with "yeojohnson." Appears to work well!
dow_norm1 = cbind(dow[,1:3], volume = dow_norm$volume$x.t, percent_change_price = dow_norm$percent_change_price$x.t,
percent_change_volume_over_last_wk = dow_norm$percent_change_volume_over_last_wk$x.t,
previous_weeks_volume = dow_norm$previous_weeks_volume$x.t, percent_change_next_weeks_price =
dow_norm$percent_change_next_weeks_price$x.t, days_to_next_dividend = dow_norm$days_to_next_dividend$x.t ) #combine factor data with normalized data and leaving out the index column ("observation")
grid.arrange(ggplot(dow_norm1, aes(volume)) + geom_boxplot(),
ggplot(dow_norm1, aes(percent_change_price)) + geom_boxplot(),
ggplot(dow_norm1, aes(percent_change_volume_over_last_wk)) + geom_boxplot(),
ggplot(dow_norm1, aes(previous_weeks_volume)) + geom_boxplot(),
ggplot(dow_norm1, aes(percent_change_next_weeks_price)) + geom_boxplot(),
ggplot(dow_norm1, aes(days_to_next_dividend)) + geom_boxplot(),
ncol = 2,
bottom = 'Figure X.X: Boxplots of Numerical Values')
#Split into train & test data sets
#Per the case study, quarter 1 will be used as the training data set and quarter 2 will be test data set
dow_train = dow_norm1[dow_norm1$quarter==1,]
dow_test = dow_norm1[dow_norm1$quarter==2,]
## Logistic Model
log.model8 = glm(percent_change_next_weeks_price ~ . , data = dow_train)
summary(log.model8)
#Predictions
dow_test$PredPercentChange = predict.glm(log.model8, newdata = dow_test, type = "response")
actual_vs_pred = data.frame(Actual = dow_test$percent_change_next_weeks_price, Predicted = dow_test$PredPercentChange)
rmse = sqrt(mean((actual_vs_pred$Actual - actual_vs_pred$Predicted)^2))
print(paste("RMSE:", rmse))
# Set a threshold to classify the predicted percentage change
# if the predicted change is greater than 0, classify it as an increase
dow_test$Direction = ifelse(dow_test$percent_change_next_weeks_price > 0, 1, 0)
dow_test$Direction = as.factor(dow_test$Direction)
dow_test$PredDirection = ifelse(dow_test$PredPercentChange > 0, 1, 0)
dow_test$PredDirection = as.factor(dow_test$PredDirection)
# Confusion Matrix to compare actual vs predicted directional movements
conf_matrix = caret::confusionMatrix(dow_test$PredDirection, dow_test$Direction, positive = "1")
print(conf_matrix)
# accuracy, sensitivity, and specificity
accuracy = conf_matrix$overall["Accuracy"]
sensitivity = conf_matrix$byClass["Sensitivity"]
specificity = conf_matrix$byClass["Specificity"]
print(paste("Accuracy:", accuracy))
print(paste("Sensitivity:", sensitivity))
print(paste("Specificity:", specificity))
### LDA Model ###
# LDA Feature Selection
rand_f.model = randomForest::randomForest(percent_change_next_weeks_price ~ ., data = dow_train)
varImpPlot(rand_f.model,
sort = T,
n.var = 10,
main = "Figure X. Variable Important plot")
# SVR Model with Grid Search for Hyper parameter Tuning
# Define tuning grid for cost and gamma (for radial kernel)
tune_grid <- expand.grid(C = c(0.01, 0.1, 1, 10, 100),
sigma = c(0.001, 0.01, 0.1, 1))
# Tuning Radial Basis Function (RBF) kernel SVM
set.seed(123)
svr_tune <- tune(svm, percent_change_next_weeks_price ~ ., data = dow_train,
type = "eps-regression",
kernel = "radial",
ranges = list(cost = tune_grid$C, gamma = tune_grid$sigma),
scale = FALSE)  # Don't scale inside the SVM function, we've already done that
# Best model based on cross-validation
best_model <- svr_tune$best.model
print(svr_tune)
# Test the tuned SVM model
pred_svr <- predict(best_model, newdata = dow_test)
#RMSE
rmse = sqrt(mean((dow_test$percent_change_next_weeks_price - pred_svr)^2))
print(paste("RMSE:", rmse))
# Testing Other Kernels
# Linear Kernel
set.seed(123)
svr_linear <- svm(percent_change_next_weeks_price ~ ., data = dow_train,
type = "eps-regression",
kernel = "linear",
cost = best_model$cost,
scale = FALSE)
pred_linear <- predict(svr_linear, newdata = dow_test)
#RMSE
rmse = sqrt(mean((dow_test$percent_change_next_weeks_price - pred_linear)^2))
print(paste("RMSE:", rmse))
# Polynomial Kernel (degree 3)
set.seed(123)
svr_poly <- svm(percent_change_next_weeks_price ~ ., data = dow_train,
type = "eps-regression",
kernel = "polynomial",
cost = best_model$cost,
degree = 3,
scale = FALSE)
pred_poly <- predict(svr_poly, newdata = dow_test)
#RMSE
rmse = sqrt(mean((dow_test$percent_change_next_weeks_price - pred_poly)^2))
print(paste("RMSE:", rmse))
